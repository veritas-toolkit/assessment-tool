<h3>Group Fairness</h3>

<div>
    The table below lists the values and respective uncertainties of fairness metrics.
    The uncertainties in the fairness metrics are measured using bootstrap methods with 50 replications and
    5-95% confidence intervals used and the plus-minus intervals representing two standard deviations.
    The primary fairness metric is marked in red.
</div>

<div>
    Fairness threshold is calculated based on fairness threshold input.
    Fairness conclusion will be generated by comparing fairness threshold and absolute difference between the fairness
    metrics
    and neutral position. Note that if the metric is ratio based, neutral position is 1;
    if metric is parity based, neutral position is 0);
    if the absolute difference is lower than the fairness threshold, the fairness conclusion would be fair.
</div>

<div>
    <div class="table_box">
        <div class="table_title">
            Fairness metrics for <b>gender</b>
        </div>
        <table>
            <thead>
            <tr>
                <th>Fairness Metric</th>
                <th>Value</th>
            </tr>
            </thead>
            <tbody>
            <tr>
                <td class="metric_name">Disparate Impact</td>
                <td class="metric_value">1.144 +/- 0.030</td>
            </tr>
            <tr>
                <td class="metric_name">Equal Opportunity Ratio</td>
                <td class="metric_value">1.021 +/- 0.012</td>
            </tr>
            <tr class="fair_metric_row">
                <td class="metric_name">False Positive Rate Ratio</td>
                <td class="metric_value">4.677 +/- 3.252</td>
            </tr>
            <tr>
                <td class="metric_name">True Negative Rate Ratio</td>
                <td class="metric_value">0.867 +/- 0.041</td>
            </tr>
            <tr>
                <td class="metric_name">False Negative Rate Ratio</td>
                <td class="metric_value">0.527 +/- 0.219</td>
            </tr>
            <tr>
                <td class="metric_name">Positive Predictive Ratio</td>
                <td class="metric_value">0.985 +/- 0.008</td>
            </tr>
            <tr>
                <td class="metric_name">Negative Predictive Ratio</td>
                <td class="metric_value">0.989 +/- 0.056</td>
            </tr>
            <tr>
                <td class="metric_name">False Discovery Rate Ratio</td>
                <td class="metric_value">2.542 +/- 1.806</td>
            </tr>
            <tr>
                <td class="metric_name">False Omission Rate Ratio</td>
                <td class="metric_value">1.067 +/- 0.376</td>
            </tr>
            <tr>
                <td class="metric_name">Equalized Odds Ratio</td>
                <td class="metric_value">0.575 +/- 0.023</td>
            </tr>
            <tr>
                <td class="metric_name">Negative Equalized Odds Ratio</td>
                <td class="metric_value">0.427 +/- 0.021</td>
            </tr>
            <tr>
                <td class="metric_name">Calibration by Group Ratio</td>
                <td class="metric_value">0.497 +/- 0.022</td>
            </tr>
            <tr>
                <td class="metric_name">AUC Ratio</td>
                <td class="metric_value">0.992 +/- 0.127</td>
            </tr>
            <tr>
                <td class="metric_name">Log-loss Ratio</td>
                <td class="metric_value">0.854 +/- 0.108</td>
            </tr>
            <tr>
                <td class="metric_name">Mutual Information Independence</td>
                <td class="metric_value">0.014 +/- 0.006</td>
            </tr>
            <tr>
                <td class="metric_name">Mutual Information Separation</td>
                <td class="metric_value">0.786 +/- 0.022</td>
            </tr>
            <tr>
                <td class="metric_name">Mutual Information Sufficiency</td>
                <td class="metric_value">0.002 +/- 0.002</td>
            </tr>
            </tbody>
        </table>
    </div>
    <div>Fairness Threshold Input: 80%</div>
    <div>Fairness Threshold: 0.2</div>
    <div>Fairness Conclusion: unfair</div>
</div>
<div>
    <div class="table_box">
        <div class="table_title">
            Fairness metrics for <b>race</b>
        </div>
        <table>
            <thead>
            <tr>
                <th>Fairness Metric</th>
                <th>Value</th>
            </tr>
            </thead>
            <tbody>
            <tr>
                <td class="metric_name">Disparate Impact</td>
                <td class="metric_value">0.992 +/- 0.040</td>
            </tr>
            <tr>
                <td class="metric_name">Equal Opportunity Ratio</td>
                <td class="metric_value">1.004 +/- 0.016</td>
            </tr>
            <tr class="fair_metric_row">
                <td class="metric_name">False Positive Rate Ratio</td>
                <td class="metric_value">0.188 +/- 0.253</td>
            </tr>
            <tr>
                <td class="metric_name">True Negative Rate Ratio</td>
                <td class="metric_value">1.086 +/- 0.036</td>
            </tr>
            <tr>
                <td class="metric_name">False Negative Rate Ratio</td>
                <td class="metric_value">0.895 +/- 0.471</td>
            </tr>
            <tr>
                <td class="metric_name">Positive Predictive Ratio</td>
                <td class="metric_value">1.017 +/- 0.007</td>
            </tr>
            <tr>
                <td class="metric_name">Negative Predictive Ratio</td>
                <td class="metric_value">1.022 +/- 0.067</td>
            </tr>
            <tr>
                <td class="metric_name">False Discovery Rate Ratio</td>
                <td class="metric_value">0.184 +/- 0.240</td>
            </tr>
            <tr>
                <td class="metric_name">False Omission Rate Ratio</td>
                <td class="metric_value">0.869 +/- 0.398</td>
            </tr>
            <tr>
                <td class="metric_name">Equalized Odds Ratio</td>
                <td class="metric_value">0.465 +/- 0.016</td>
            </tr>
            <tr>
                <td class="metric_name">Negative Equalized Odds Ratio</td>
                <td class="metric_value">0.539 +/- 0.019</td>
            </tr>
            <tr>
                <td class="metric_name">Calibration by Group Ratio</td>
                <td class="metric_value">0.499 +/- 0.026</td>
            </tr>
            <tr>
                <td class="metric_name">AUC Ratio</td>
                <td class="metric_value">1.005 +/- 0.201</td>
            </tr>
            <tr>
                <td class="metric_name">Log-loss Ratio</td>
                <td class="metric_value">0.867 +/- 0.153</td>
            </tr>
            <tr>
                <td class="metric_name">Mutual Information Independence</td>
                <td class="metric_value">0.000 +/- 0.001</td>
            </tr>
            <tr>
                <td class="metric_name">Mutual Information Separation</td>
                <td class="metric_value">0.644 +/- 0.041</td>
            </tr>
            <tr>
                <td class="metric_name">Mutual Information Sufficiency</td>
                <td class="metric_value">0.003 +/- 0.003</td>
            </tr>
            </tbody>
        </table>
    </div>
    <div>Fairness Threshold Input: 80%</div>
    <div>Fairness Threshold: 0.2</div>
    <div>Fairness Conclusion: unfair</div>
</div>
<div>
    <div class="table_box">
        <div class="table_title">
            Fairness metrics for <b>gender-race</b>
        </div>
        <table>
            <thead>
            <tr>
                <th>Fairness Metric</th>
                <th>Value</th>
            </tr>
            </thead>
            <tbody>
            <tr>
                <td class="metric_name">Disparate Impact</td>
                <td class="metric_value">1.148 +/- 0.032</td>
            </tr>
            <tr>
                <td class="metric_name">Equal Opportunity Ratio</td>
                <td class="metric_value">1.022 +/- 0.013</td>
            </tr>
            <tr class="fair_metric_row">
                <td class="metric_name">False Positive Rate Ratio</td>
                <td class="metric_value">4.299 +/- 3.076</td>
            </tr>
            <tr>
                <td class="metric_name">True Negative Rate Ratio</td>
                <td class="metric_value">0.857 +/- 0.051</td>
            </tr>
            <tr>
                <td class="metric_name">False Negative Rate Ratio</td>
                <td class="metric_value">0.521 +/- 0.241</td>
            </tr>
            <tr>
                <td class="metric_name">Positive Predictive Ratio</td>
                <td class="metric_value">0.984 +/- 0.009</td>
            </tr>
            <tr>
                <td class="metric_name">Negative Predictive Ratio</td>
                <td class="metric_value">0.988 +/- 0.063</td>
            </tr>
            <tr>
                <td class="metric_name">False Discovery Rate Ratio</td>
                <td class="metric_value">2.313 +/- 1.668</td>
            </tr>
            <tr>
                <td class="metric_name">False Omission Rate Ratio</td>
                <td class="metric_value">1.075 +/- 0.437</td>
            </tr>
            <tr>
                <td class="metric_name">Equalized Odds Ratio</td>
                <td class="metric_value">0.579 +/- 0.028</td>
            </tr>
            <tr>
                <td class="metric_name">Negative Equalized Odds Ratio</td>
                <td class="metric_value">0.421 +/- 0.026</td>
            </tr>
            <tr>
                <td class="metric_name">Calibration by Group Ratio</td>
                <td class="metric_value">0.498 +/- 0.025</td>
            </tr>
            <tr>
                <td class="metric_name">AUC Ratio</td>
                <td class="metric_value">0.992 +/- 0.133</td>
            </tr>
            <tr>
                <td class="metric_name">Log-loss Ratio</td>
                <td class="metric_value">0.834 +/- 0.114</td>
            </tr>
            <tr>
                <td class="metric_name">Mutual Information Independence</td>
                <td class="metric_value">0.015 +/- 0.006</td>
            </tr>
            <tr>
                <td class="metric_name">Mutual Information Separation</td>
                <td class="metric_value">0.773 +/- 0.025</td>
            </tr>
            <tr>
                <td class="metric_name">Mutual Information Sufficiency</td>
                <td class="metric_value">0.002 +/- 0.003</td>
            </tr>
            </tbody>
        </table>
    </div>
    <div>Fairness Threshold Input: 80%</div>
    <div>Fairness Threshold: 0.2</div>
    <div>Fairness Conclusion: unfair</div>
</div>


<h3>Individual Fairness</h3>
For individual fairness, the consistency score is 0.879.